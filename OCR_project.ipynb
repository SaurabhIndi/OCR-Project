{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkK5eYo5BewdwFJFXp+rym",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaurabhIndi/OCR-project/blob/main/OCR_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# !pip install paddleocr\n",
        "# !pip install paddlepaddle==2.4.2\n",
        "import cv2\n",
        "import numpy as np\n",
        "from paddleocr import PaddleOCR\n",
        "\n",
        "# Initialize CNN-based OCR (PaddleOCR)\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"Preprocess image for OCR (grayscale, thresholding).\"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
        "    return image, gray, thresh\n",
        "\n",
        "def template_matching(gray_image, templates, threshold=0.8):\n",
        "    \"\"\"Perform template matching for predictable fonts.\"\"\"\n",
        "    recognized_text = \"\"\n",
        "    for char, template_path in templates.items():\n",
        "        # Load template\n",
        "        template = cv2.imread(template_path, 0)\n",
        "\n",
        "        # Check if template loaded successfully\n",
        "        if template is None:\n",
        "            print(f\"Error: Could not load template from {template_path}\")\n",
        "            continue  # Skip to the next template\n",
        "\n",
        "        # Resize template if it's larger than the image\n",
        "        if template.shape[0] > gray_image.shape[0] or template.shape[1] > gray_image.shape[1]:\n",
        "            h, w = template.shape\n",
        "            scale_factor = min(gray_image.shape[0] / h, gray_image.shape[1] / w)\n",
        "            new_size = (int(w * scale_factor), int(h * scale_factor))\n",
        "            template = cv2.resize(template, new_size)\n",
        "            print(f\"Resized template '{char}' to {new_size}\")\n",
        "\n",
        "        # Print sizes for debugging (optional)\n",
        "        # print(f\"Template size ({char}): {template.shape}\")\n",
        "        # print(f\"Image size: {gray_image.shape}\")\n",
        "\n",
        "        # Match template\n",
        "        result = cv2.matchTemplate(gray_image, template, cv2.TM_CCOEFF_NORMED)\n",
        "        _, max_val, _, _ = cv2.minMaxLoc(result)\n",
        "        if max_val > threshold:\n",
        "            recognized_text += char\n",
        "    return recognized_text\n",
        "\n",
        "def cnn_ocr(image_path):\n",
        "    \"\"\"Fallback to CNN-based OCR.\"\"\"\n",
        "    result = ocr.ocr(image_path, det=True, rec=True)\n",
        "    detected_text = \"\"\n",
        "    for line in result[0]:\n",
        "        detected_text += line[1][0] + \" \"\n",
        "    return detected_text.strip()\n",
        "\n",
        "def hybrid_ocr(image_path, templates):\n",
        "    \"\"\"Combine template matching and CNN-based OCR.\"\"\"\n",
        "    _, gray, _ = preprocess_image(image_path)\n",
        "\n",
        "    # Step 1: Try template matching\n",
        "    tm_result = template_matching(gray, templates)\n",
        "\n",
        "    # Step 2: Fallback to CNN OCR if template matching fails\n",
        "    if not tm_result:\n",
        "        tm_result = cnn_ocr(image_path)\n",
        "\n",
        "    return tm_result\n",
        "\n",
        "# Define templates for predictable fonts (e.g., digital displays)\n",
        "templates = {\n",
        "    \"0\": \"templates/0.jpg\",\n",
        "    \"1\": \"templates/1.jpg\",\n",
        "    \"2\": \"templates/2.jpg\",\n",
        "    # Add paths for other digits/characters\n",
        "}\n",
        "\n",
        "# Hybrid OCR on example images\n",
        "image_paths = [\n",
        "    \"display (3).jpg\",\n",
        "    \"display (2).jpg\",\n",
        "    \"capchas (1).jpeg\",\n",
        "    \"display (1).jpg\",\n",
        "    \"capchas (2).jpeg\"\n",
        "\n",
        "]\n",
        "\n",
        "for path in image_paths:\n",
        "    print(f\"Text from {path}: {hybrid_ocr(path, templates)}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mZXw3rKhshP",
        "outputId": "02113320-84dd-477a-ee20-6db30f8bdcaa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024/11/16 19:53:58] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.10/dist-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
            "Error: Could not load template from templates/0.jpg\n",
            "Error: Could not load template from templates/1.jpg\n",
            "Error: Could not load template from templates/2.jpg\n",
            "[2024/11/16 19:54:00] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.039188385009765625\n",
            "[2024/11/16 19:54:00] ppocr DEBUG: cls num  : 1, elapsed : 0.014858484268188477\n",
            "[2024/11/16 19:54:00] ppocr DEBUG: rec_res num  : 1, elapsed : 0.3575618267059326\n",
            "Text from display (3).jpg: 2.329\n",
            "Error: Could not load template from templates/0.jpg\n",
            "Error: Could not load template from templates/1.jpg\n",
            "Error: Could not load template from templates/2.jpg\n",
            "[2024/11/16 19:54:00] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.049896240234375\n",
            "[2024/11/16 19:54:00] ppocr DEBUG: cls num  : 4, elapsed : 0.04213690757751465\n",
            "[2024/11/16 19:54:01] ppocr DEBUG: rec_res num  : 4, elapsed : 0.571570634841919\n",
            "Text from display (2).jpg: AUTO 668 AC PD\n",
            "Error: Could not load template from templates/0.jpg\n",
            "Error: Could not load template from templates/1.jpg\n",
            "Error: Could not load template from templates/2.jpg\n",
            "[2024/11/16 19:54:01] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.023192644119262695\n",
            "[2024/11/16 19:54:01] ppocr DEBUG: cls num  : 1, elapsed : 0.012834310531616211\n",
            "[2024/11/16 19:54:01] ppocr DEBUG: rec_res num  : 1, elapsed : 0.1464674472808838\n",
            "Text from capchas (1).jpeg: N6R6VR\n",
            "Error: Could not load template from templates/0.jpg\n",
            "Error: Could not load template from templates/1.jpg\n",
            "Error: Could not load template from templates/2.jpg\n",
            "[2024/11/16 19:54:01] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.02613544464111328\n",
            "[2024/11/16 19:54:01] ppocr DEBUG: cls num  : 1, elapsed : 0.015283584594726562\n",
            "[2024/11/16 19:54:01] ppocr DEBUG: rec_res num  : 1, elapsed : 0.16247868537902832\n",
            "Text from display (1).jpg: 9116\n",
            "Error: Could not load template from templates/0.jpg\n",
            "Error: Could not load template from templates/1.jpg\n",
            "Error: Could not load template from templates/2.jpg\n",
            "[2024/11/16 19:54:01] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.025224685668945312\n",
            "[2024/11/16 19:54:01] ppocr DEBUG: cls num  : 1, elapsed : 0.01415252685546875\n",
            "[2024/11/16 19:54:01] ppocr DEBUG: rec_res num  : 1, elapsed : 0.14167118072509766\n",
            "Text from capchas (2).jpeg: HTTXB6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nhEk57LmgtcA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}